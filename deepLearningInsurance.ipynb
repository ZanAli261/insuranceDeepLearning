{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning with Insurance Data \n",
    "Data downloaded from kaggle\n",
    "kaggle datasets download -d navya1099/insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15290 entries, 0 to 15289\n",
      "Data columns (total 8 columns):\n",
      "Policy Number         15290 non-null int64\n",
      "Number of Vehicles    15290 non-null int64\n",
      "Average Age           15290 non-null float64\n",
      "Gender Dummy          15290 non-null int64\n",
      "Married Dummy         15290 non-null int64\n",
      "Avg Veh Age           15290 non-null float64\n",
      "Fuel Type Dummy       15290 non-null int64\n",
      "Losses                15290 non-null float64\n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 955.7 KB\n",
      "None\n",
      "   Policy Number  Number of Vehicles  Average Age  Gender Dummy  \\\n",
      "0         150023                   1         20.6             1   \n",
      "1         152720                   1         42.4             0   \n",
      "2         174207                   1         42.4             1   \n",
      "3         139895                   1         42.4             0   \n",
      "4         174407                   1         20.6             1   \n",
      "\n",
      "   Married Dummy  Avg Veh Age  Fuel Type Dummy      Losses  \n",
      "0              0        12.97                0  203.319595  \n",
      "1              1         8.02                0  402.197302  \n",
      "2              0         2.50                1  553.132096  \n",
      "3              0        12.97                0  292.430579  \n",
      "4              1        12.97                0  246.540576  \n",
      "       Policy Number  Number of Vehicles   Average Age  Gender Dummy  \\\n",
      "count   15290.000000        15290.000000  15290.000000  15290.000000   \n",
      "mean   149910.276651            2.495880     42.341969      0.493329   \n",
      "std     28948.806631            0.953776     16.976615      0.499972   \n",
      "min    100002.000000            1.000000     20.600000      0.000000   \n",
      "25%    124842.000000            2.000000     20.600000      0.000000   \n",
      "50%    149872.000000            2.000000     42.400000      0.000000   \n",
      "75%    175011.000000            3.000000     65.100000      1.000000   \n",
      "max    200000.000000            4.000000     65.100000      1.000000   \n",
      "\n",
      "       Married Dummy   Avg Veh Age  Fuel Type Dummy        Losses  \n",
      "count   15290.000000  15290.000000     15290.000000  15290.000000  \n",
      "mean        0.490974      8.656579         0.236756    389.859718  \n",
      "std         0.499935      4.084988         0.425105    253.729433  \n",
      "min         0.000000      2.500000         0.000000     12.534521  \n",
      "25%         0.000000      8.020000         0.000000    226.434217  \n",
      "50%         0.000000      8.020000         0.000000    354.937874  \n",
      "75%         1.000000     12.970000         0.000000    488.676927  \n",
      "max         1.000000     12.970000         1.000000   3500.000000  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:\\\\Data')\n",
    "insur = pd.read_csv('Insurance_Data.csv')\n",
    "print(insur.info())\n",
    "print(insur.head())\n",
    "print(insur.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15290 7\n",
      "15290 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = insur.drop('Losses', axis=1)\n",
    "loss = insur.Losses\n",
    "print(features.shape[0], features.shape[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, loss, test_size=0.3, random_state=261\n",
    "                                                   )\n",
    "scaler = StandardScaler()\n",
    "# Use on the training data to fit the scaler, then transfrom both the training and test data with result \n",
    "# so data is scaled with same mean and vaiance\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape[0] + X_test.shape[0], X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: 0.7712615899772785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(7, 7, 7), activation='relu', solver='adam', \n",
    "                   learning_rate_init=0.01, random_state=261)\n",
    "mlp.fit(X_train, y_train)\n",
    "preds = mlp.predict(X_test)\n",
    "print('r^2: ' + str(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
